{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scriptpath /home/biddisco/src/ghex/benchmarks/scripts \n",
      "Hostname oryx2\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import math\n",
    "import numpy as np\n",
    "import inspect\n",
    "import os.path\n",
    "import time\n",
    "import subprocess\n",
    "from IPython.display import Image, display, HTML\n",
    "import importlib\n",
    "import socket\n",
    "#\n",
    "hostname = socket.gethostname()\n",
    "if hostname.startswith('daint'):\n",
    "    hostname = 'daint'\n",
    "scriptname = inspect.getframeinfo(inspect.currentframe()).filename\n",
    "scriptpath = os.path.dirname(os.path.abspath(scriptname))\n",
    "print(f'Scriptpath {scriptpath} \\nHostname {hostname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this string will be substituted by cmake \n",
    "bin_dir = \"@BIN_DIR@\"\n",
    "run_dir = \"@RUN_DIR@\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook generate-ghex.ipynb to script\n",
      "[NbConvertApp] Writing 8818 bytes to generate-ghex.py\n"
     ]
    }
   ],
   "source": [
    "def is_notebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "    \n",
    "if is_notebook():\n",
    "    # this makes the notebook wider on a larger screen using %x of the display\n",
    "    display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "    # save this notebook as a raw python file as well please\n",
    "    get_ipython().system('jupyter nbconvert --to script generate-ghex.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# experimental code to try to generate a sensible number of messages given a message size\n",
    "#\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def normalized_sigmoid_fkt(center, width, x):\n",
    "   '''\n",
    "   Returns array of a horizontal mirrored normalized sigmoid function\n",
    "   output between 0 and 1\n",
    "   '''\n",
    "   s = 1/(1+np.exp(width*(x-center)))\n",
    "   return s \n",
    "   #return 1*(s-min(s))/(max(s)-min(s)) # normalize function to 0-1\n",
    "\n",
    "def num_messages(vmax, vmin, center, width, x):\n",
    "    s = 1 / (1 + np.exp(width*(x-center)))\n",
    "    return vmin + (vmax-vmin)*s #(s-vmin)/(vmax-vmin) # normalize function to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cscs = {}\n",
    "\n",
    "cscs[\"oryx2\"] = {\n",
    "  \"Cores\": 8,\n",
    "  \"Threads per core\": 2,\n",
    "  \"Allowed rpns\": [1, 2],\n",
    "  \"thread_array\": [1,2,4,8],    \n",
    "  \"sleeptime\":0,\n",
    "  \"Run command\": \"mpiexec -n {total_ranks} --oversubscribe\",\n",
    "  \"Batch preamble\": \"\"\"\n",
    "#!/bin/bash -l\n",
    "\n",
    "# Env\n",
    "export OMP_NUM_THREADS={threads}\n",
    "\n",
    "# Commands\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# mc nodes config\n",
    "cscs[\"daint\"] = {\n",
    "  \"Cores\": 36,\n",
    "  \"Threads per core\": 2,\n",
    "  \"Allowed rpns\": [1, 2],\n",
    "  \"thread_array\": [1,2,4,8,16,32],\n",
    "  \"sleeptime\":0.25,\n",
    "  \"Run command\": \"srun -n {total_ranks} -c {threads_per_rank}\",\n",
    "  \"Batch preamble\": \"\"\"\n",
    "#!/bin/bash -l\n",
    "#SBATCH --job-name={run_name}_{nodes}_{size}_{inflight}_{threads}\n",
    "#SBATCH --time={time_min}\n",
    "#SBATCH --nodes={nodes}\n",
    "#SBATCH --partition=normal\n",
    "#SBATCH --account=csstaff\n",
    "#SBATCH --constraint=mc\n",
    "#SBATCH --output=output.txt\n",
    "#SBATCH --error=error.txt\n",
    "\n",
    "# Env\n",
    "export MPICH_MAX_THREAD_SAFETY=multiple\n",
    "export OMP_NUM_THREADS={threads}\n",
    "export MKL_NUM_THREADS={threads}\n",
    "\n",
    "# Debug\n",
    "module list &> modules.txt\n",
    "printenv > env.txt\n",
    "\n",
    "# Commands\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Generate Job script preamble\n",
    "#\n",
    "def init_job_text(system, run_name, time_min, nodes, threads, inflight, size):\n",
    "    return system[\"Batch preamble\"].format(run_name=run_name, \n",
    "                                           time_min=time_min, \n",
    "                                           nodes=nodes,\n",
    "                                           size=size,\n",
    "                                           inflight=inflight,\n",
    "                                           threads=threads).strip()\n",
    "#\n",
    "# create a directory name from params\n",
    "#\n",
    "def make_job_directory(fdir,name, transport, nodes, threads, inflight, size):\n",
    "    return f'{fdir}/{name}_{transport}_{nodes}_{threads}_{inflight}_{size}'\n",
    "\n",
    "#\n",
    "# create the launch command-line\n",
    "#\n",
    "def run_command(system, total_ranks, cpus_per_rank):\n",
    "    threads_per_rank = system[\"Threads per core\"] * cpus_per_rank\n",
    "    return system[\"Run command\"].format(total_ranks=total_ranks, cpus_per_rank=cpus_per_rank, threads_per_rank=threads_per_rank)\n",
    "\n",
    "#\n",
    "# create dir + write final script for sbatch/shell or other job launcher \n",
    "#\n",
    "def write_job_file(system, launch_file, job_dir, job_text, suffix=''):\n",
    "    job_path = os.path.expanduser(job_dir)\n",
    "    os.makedirs(job_path, exist_ok=True)\n",
    "    job_file = f\"{job_path}/job_{suffix}.sh\"\n",
    "    with open(job_file, \"w\") as f:\n",
    "        f.write(job_text)\n",
    "\n",
    "    print(f\"Submitting : {job_path} : {job_file}\")\n",
    "    launchstring  = f'sbatch --chdir={job_path} {job_file}\\n'\n",
    "    launchstring += 'sleep ' + str(system['sleeptime']) + '\\n'\n",
    "    launch_file.write(launchstring)\n",
    "\n",
    "#\n",
    "# application specific commmands/flags/options that go into the job script\n",
    "#\n",
    "def ghex(system, bin_dir, timeout, transport, progs, nodes, threads, msg, size, inflight, extra_flags=\"\", env=\"\"):\n",
    "    total_ranks = 2\n",
    "    whole_cmd = \"\"\n",
    "    # mpi oes not have suffix, other transport layers use '_libfabric', '_ucx', eetc\n",
    "    suffix = f'_{transport}' if transport!='mpi' else ''\n",
    "    for prog in progs:\n",
    "        \n",
    "        # generate the program commmand with command line params\n",
    "        cmd = f\"{bin_dir}/{prog}{suffix} {msg} {size} {inflight}\"\n",
    "        \n",
    "        # get the launch command (mpiexec, srun, etc)\n",
    "        run_cmd = run_command(system, total_ranks, threads)\n",
    "        \n",
    "        # simple version of benchmark\n",
    "        temp = \"\\n\" + f\"{env} timeout {timeout} {run_cmd} {cmd} >> {prog}_{msg}_{size}_{inflight}.out\".strip()\n",
    "        whole_cmd += temp +'\\n'\n",
    "        \n",
    "        # for libfabric, run benchmark again with extra environment options to control execution\n",
    "        if transport=='libfabric':\n",
    "            lf_env = env + 'LIBFABRIC_AUTO_PROGRESS=1'\n",
    "            temp = \"\\n\" + f\"{lf_env} timeout {timeout} {run_cmd} {cmd} >> {prog}_{msg}_{size}_{inflight}.out\".strip()\n",
    "            whole_cmd += temp +'\\n'\n",
    "            \n",
    "            lf_env = env + 'LIBFABRIC_ENDPOINT_MULTI=1'\n",
    "            temp = \"\\n\" + f\"{lf_env} timeout {timeout} {run_cmd} {cmd} >> {prog}_{msg}_{size}_{inflight}.out\".strip()\n",
    "            whole_cmd += temp +'\\n'\n",
    "            \n",
    "            lf_env = env + 'LIBFABRIC_ENDPOINT_THREADLOCAL=1'\n",
    "            temp = \"\\n\" + f\"{lf_env} timeout {timeout} {run_cmd} {cmd} >> {prog}_{msg}_{size}_{inflight}.out\".strip()\n",
    "            whole_cmd += temp +'\\n'\n",
    "            \n",
    "            lf_env = env + 'LIBFABRIC_AUTO_PROGRESS=1 ' + 'LIBFABRIC_ENDPOINT_MULTI=1'\n",
    "            temp = \"\\n\" + f\"{lf_env} timeout {timeout} {run_cmd} {cmd} >> {prog}_{msg}_{size}_{inflight}.out\".strip()\n",
    "            whole_cmd += temp +'\\n'\n",
    "            \n",
    "            lf_env = env + 'LIBFABRIC_AUTO_PROGRESS=1 ' + 'LIBFABRIC_ENDPOINT_THREADLOCAL=1'\n",
    "            temp = \"\\n\" + f\"{lf_env} timeout {timeout} {run_cmd} {cmd} >> {prog}_{msg}_{size}_{inflight}.out\".strip()\n",
    "            whole_cmd += temp +'\\n'\n",
    "            \n",
    "    return whole_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = cscs[hostname]\n",
    "#\n",
    "job_name       = 'ghex-benchmark'\n",
    "timeout        = 180        # seconds per benchmark\n",
    "time_min       = timeout*20 # total time estimate  \n",
    "timestr        = time.strftime('%H:%M:%S', time.gmtime(time_min))\n",
    "ranks_per_node = 1\n",
    "nodes_arr = [2]\n",
    "trans_arr = ['libfabric', 'mpi']\n",
    "thrd_arr  = system['thread_array']\n",
    "size_arr  = [1,1000,10000,100000,500000,1000000]\n",
    "nmsg_lut  = {1:500000, \n",
    "             1000:500000, \n",
    "             5000:250000,\n",
    "             10000:250000, \n",
    "             50000:250000,\n",
    "             100000:250000,\n",
    "             200000:250000,\n",
    "             500000:100000,\n",
    "             1000000:50000,\n",
    "             2000000:25000}\n",
    "\n",
    "#for i in size_arr:\n",
    "#    print(int(num_messages(1E6, 25E3, 1E5, 1E-5, i)))\n",
    "\n",
    "flight_arr= [1,2,4,8,16,32,64]\n",
    "prog_arr  = [\"ghex_p2p_bi_cb_avail_mt\", \"ghex_p2p_bi_cb_wait_mt\", \"ghex_p2p_bi_ft_avail_mt\", \"ghex_p2p_bi_ft_wait_mt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756\n"
     ]
    }
   ],
   "source": [
    "combos = 0\n",
    "\n",
    "job_launch = f\"{run_dir}/launch.sh\"\n",
    "job_launch_file = open(job_launch, \"w\")\n",
    "\n",
    "# generate all combinations in one monster loop\n",
    "for nodes, transport, threads, size, inflight in product(\n",
    "    nodes_arr, trans_arr, thrd_arr, size_arr, flight_arr):        \n",
    "        \n",
    "    combos += 1 \n",
    "    \n",
    "    extra_flags = \"\"    \n",
    "    suffix = \"\"\n",
    "    # number of messages (niter)\n",
    "    msg = int(num_messages(1E6, 25E3, 1E5, 1E-5, size))\n",
    "    msg = nmsg_lut[size]\n",
    "    # create the output directory for each job\n",
    "    job_dir = make_job_directory(run_dir, 'ghex', transport, nodes, threads, inflight, size)\n",
    "    \n",
    "    # first part of boiler plate job script\n",
    "    job_text = init_job_text(system, job_name, timestr, nodes, threads, size, msg)    \n",
    "    \n",
    "    # application specific part of job script\n",
    "    job_text += ghex(\n",
    "        system,\n",
    "        bin_dir,\n",
    "        timeout, \n",
    "        transport,\n",
    "        prog_arr,\n",
    "        nodes,\n",
    "        threads,\n",
    "        msg,\n",
    "        size,\n",
    "        inflight,\n",
    "        suffix,\n",
    "        extra_flags,\n",
    "    )\n",
    "    \n",
    "    # uncomment this run jobs\n",
    "    write_job_file(system, job_launch_file, job_dir, job_text)\n",
    "    # print(job_dir, '\\n', job_text, '\\n\\n\\n\\n')\n",
    "\n",
    "print(combos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
